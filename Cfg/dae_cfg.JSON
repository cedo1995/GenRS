{
  "use_gpu" : true,
  "batch_size" : 500,
  "batch_size_val" : 2000,
  "batch_size_test" : 2000,
  "tot_anneal_steps" : 200000,
  "anneal_cap" : 0.2,
  "input_p": 200,
  "lambda" : 0.01,
  "lr" : 0.001,
  "n_epochs": 200,
  "random_seed" : 98765
}
